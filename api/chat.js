const OpenAI = require("openai");

module.exports = async (req, res) => {
  console.log("ğŸ“© Nueva peticiÃ³n recibida");
  console.log("ğŸ§  Clave API presente:", !!process.env.OPENAI_API_KEY);

  if (!process.env.OPENAI_API_KEY) {
    return res.status(500).send("Falta OPENAI_API_KEY en el servidor");
  }

  const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
  });

  try {
    const { msg } = req.query;
    console.log("ğŸ—¨ï¸ Mensaje recibido:", msg);

    if (!msg) {
      return res.status(400).send("Falta parÃ¡metro msg");
    }

    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo", // usa este modelo por compatibilidad
      messages: [
        { role: "system", content: "Eres un bot simpÃ¡tico para Twitch. Responde corto y directo." },
        { role: "user", content: msg },
      ],
    });

    console.log("âœ… Respuesta generada correctamente");
    const respuesta = completion.choices[0].message.content;
    res.status(200).send(respuesta);
  } catch (error) {
    console.error("ğŸ”¥ Error detectado:", error);
    res.status(500).send(`Error interno: ${error.message}`);
  }
};

